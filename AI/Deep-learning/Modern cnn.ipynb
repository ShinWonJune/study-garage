{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet\n",
    "#### key ideas\n",
    "- Rectified Linear Unit activation\n",
    "- GPI implementation (2 gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG\n",
    "- 3X3 Conv Layer 만 사용\n",
    "    - 3x3 두개가 5x5하나보다 적은 parameter를 갖는다.\n",
    "- filter를 작게해주는게 같은 면적으로 filtering 하는경우 더 효율적이다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet\n",
    "- 1x1 conv layer 사용 -> Channel-wise Dimension을 줄여줌\n",
    "- 1x1를 적절히 사용하는게 parameter를 줄일 수 있는 방법중 하나다\n",
    "- spatial(weith,heigth)을 줄이고 싶을 경우에도 바로 3x3 conv를 하기 보다, 1x1로 먼저 depth를 줄여준 다음 3x3을 해주는게 효율적이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "- skip- connection을 통해 layer를 건너뛴 data를 더해준다\n",
    "- skip connection 이전에는 layer가 깊어질수록 성능이 안좋아졌는데 이를 극복해줌, 깊은 layer의 가능성을 열어줌\n",
    "- 1x1 conv로 channel을 줄이고, 3x3 or 5x5 conv로 receptive field를 늘려주며 parameter는 줄여주면서 모델 자체의 depth를 늘려주어 성능을 높힌다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DensNet\n",
    "- Dense Block -> Transition Block -> D.B -> T.B 를 반복함\n",
    "- Dense Block : 각 layer의 feature map을 concatenate해서 엄청 두껍게 만듬\n",
    "- Transition Block: Batch Norm-> 1x1 conv-> 2x2 avgPooling을 통해 얇게 만듬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보통 resnet 이나 DensEet 사용하라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da2004fe03f436a9a81b9c95e439c4add18d0165a64bc8b11e0efabfe79c313a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
