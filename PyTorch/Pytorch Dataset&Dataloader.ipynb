{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델에 데이터가 들어가는 과정(번호가 순서는 아님)\n",
    "1. 데이터를 모은다(collect, clean, preprocess)\n",
    "2. Dataset Class로 전달\n",
    "    - `__init__()`   : 초기 데이터를 어떻게 불러오는지 정의\n",
    "        - file에서 불러오는지, 어떤 dir에서 불러오는지 등\n",
    "    - `__len__()`    :데이터 길이\n",
    "    - `__getitem__()`: __map-style__ 하나의 데이터를 불러올 때 어떻게 반환하는지 선언\n",
    "3. transforms\n",
    "    - 이미지 전처리, data augmentation 에서 data 변환 등의 전처리.\n",
    "    - ToTensor() 를 거처 tensor형태로 데이터 받는다.\n",
    "        - 데이터를 tensor로 바꾸는 작업은 transform(totensor)에서 일어남.\n",
    "4. DataLoader\n",
    "    - 데이터를 묶어서 모델에 넣어주는 역할\n",
    "    - batch\n",
    "    - shuffle\n",
    "    - 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 클래스\n",
    "- 데이터 입력 형태를 정의하는 클래스\n",
    "- 데이터 입력하는 방식의 __표준화__. 모든 데이터에 적용됨\n",
    "- image, text, audio 등 형태에 따른 다른 입력 정의\n",
    "\n",
    "#### 유의점\n",
    "- 데이터 형태에 따라 각 함수를 다르게 정의함\n",
    "- 모든 것을 데이터 생성 시점에 처리할 필요 없음\n",
    "    - image의 Tensor 변화는 학습에 필요한 시점에 변환 (transorm을 통해)\n",
    "- 데이터 넷에 대한 표준화된 처리방법 제공 필요\n",
    "    - 후속 연구자에게 빛\n",
    "- Hugging Face 등 표준화된 라이브러리 사용\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관련 모듈\n",
    "- torch.utils.data\n",
    "    - 데이터셋을 불러오고 자르고 섞는 도구 모음 모듈\n",
    "- torch.utils.data.Dataset : 모델을 학습시키기 위한 데이터셋의 표준을 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    # 초기 데이터를 어떻게 불러오는지 정의\n",
    "    # file에서 불러오는지, 어떤 dir에서 불러오는지 등\n",
    "    def __init__(self, text, labels):\n",
    "            self.labels = labels\n",
    "            self.data = text\n",
    "\n",
    "    def __len__(self):\n",
    "            return len(self.labels)\n",
    "\n",
    "    # index 값을 주었을 때, 반환되는 데이터의 형태 (X,Y) \n",
    "    # 전처리하고 데이터 증강이 진행됨.\n",
    "    def __getitem__(self, idx):\n",
    "            label = self.labels[idx]\n",
    "            text = self.data[idx]\n",
    "            # 반환되는 형태\n",
    "            sample = {\"Text\": text, \"Class\": label}\n",
    "            return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Happy', 'Amazing', 'Sad', 'Unhapy', 'Glum']\n",
    "labels = ['Positive', 'Positive', 'Negative', 'Negative', 'Negative']\n",
    "MyDataset = CustomDataset(text, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.CustomDataset"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(MyDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 클래스\n",
    "- iterable 객체 생성\n",
    "    - 객체를 iter()에 넣어주면 generater, 그 후 next()에 넣어 하나씩 호출가능\n",
    "- Data의 Batch를 생성해주는 클래스\n",
    "    -   Dataset은 하나의 데이터를 어떻게 가져올것인가.\n",
    "    -   DataLoader는 index로 여러 데이터를 묶어서 모델에 넣어줌\n",
    "- 학습 직전(GPU feed전) 데이터의 변환을 책임\n",
    "- __Tensor로 변환__ + Batch 처리가 메인 업무\n",
    "- 병렬적인 데이터 전처리 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': ['Amazing', 'Happy'], 'Class': ['Positive', 'Positive']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size = 2 --> 한번에 두개의 데이터씩 들어감\n",
    "# shuffle = True --> text,lable을 한쌍으로 두개씩 랜덤으로 뽑아 넣는다.\n",
    "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
    "next(iter(MyDataLoader))\n",
    "# 이제 gpu에 넣어줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Text': ['Amazing', 'Unhapy'], 'Class': ['Positive', 'Negative']}\n",
      "{'Text': ['Sad', 'Glum'], 'Class': ['Negative', 'Negative']}\n",
      "{'Text': ['Happy'], 'Class': ['Positive']}\n"
     ]
    }
   ],
   "source": [
    "MyDataLoader = DataLoader(MyDataset, batch_size=2, shuffle=True)\n",
    "for dataset in MyDataLoader:\n",
    "    print(dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하나의 EPIC을 돌리려면, 데이터로더가 한번 돌아가면된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader args\n",
    "\n",
    "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler = None, num_workers = 0, <br> &emsp;&emsp;&emsp;&emsp;&emsp; collate_fn = None, pin_memory=False, drop_last=False, timeout= 0, worker_init_fn= None,*,<br> &emsp;&emsp;&emsp;&emsp; &emsp;prefetch_factor =2, persistent_workers=False)\n",
    "- collate_fn\n",
    "    - [데이터, 레이블] 쌍으로 이루어진 형태를 , [데이터, 데이터,,], [레이블, 레이블,,] 형태로 바꾸어줌\n",
    "    - 언제쓰이나요\n",
    "        - text 데이터.\n",
    "        - 길이가 각각 다른 text X에 0을 padding하여 동일한 길이로 만들때.\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size\n",
    "    - int, optional, default=1\n",
    "    - 배치(batch)의 크기입니다. 데이터셋에 50개의 데이터가 있고, batch_size가 10라면 총 50/10=5, 즉 5번의 iteration만 지나면 모든 데이터를 볼 수 있습니다.\n",
    "    - 이 경우 반복문을 돌리면 (batch_size, *(data.shape))의 형태의 Tensor로 데이터가 반환됩니다. dataset에서 return하는 모든 데이터는 Tensor로 변환되어 오니 Tensor로 변환이 안되는 데이터는 에러가 납니다.<br>\n",
    "    <br>\n",
    "\n",
    "- shuffle\n",
    "    - bool, optional, default=False\n",
    "    - 데이터를 DataLoader에서 섞어서 사용하겠는지를 설정할 수 있습니다. 실험 재현을 위해 torch.manual_seed를 고정하는 것도 포인트입니다.\n",
    "    - 그냥 Dataset에서 initialize할 때, random.shuffle로 섞을 수도 있습니다.<br><br>\n",
    "\n",
    "\n",
    "- sampler\n",
    "    - Sampler, optional\n",
    "    - torch.utils.data.Sampler 객체를 사용합니다.\n",
    "    - sampler는 index를 컨트롤하는 방법입니다. 데이터의 index를 원하는 방식대로 조정합니다. 즉 index를 컨트롤하기 때문에 설정하고 싶다면 shuffle 파라미터는 False(기본값)여야 합니다.\n",
    "    - map-style에서 컨트롤하기 위해 사용하며 __len__과 __iter__를 구현하면 됩니다. 그 외의 미리 선언된 Sampler는 다음과 같습니다.\n",
    "        - SequentialSampler : 항상 같은 순서\n",
    "        - RandomSampler : 랜덤, replacemetn 여부 선택 가능, 개수 선택 가능\n",
    "        - SubsetRandomSampler : 랜덤 리스트, 위와 두 조건 불가능\n",
    "        - WeigthRandomSampler : 가중치에 따른 확률\n",
    "        - BatchSampler : batch단위로 sampling 가능\n",
    "        - DistributedSampler : 분산처리 (torch.nn.parallel.DistributedDataParallel과 함께 사용)\n",
    "\n",
    "https://subinium.github.io/pytorch-dataloader/ <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 관련 모듈\n",
    "- torchvision.dataset : torch.utils.data.Dataset을 상속하는 데이터셋 모음. MNIST, CIFAR-10 제공\n",
    "- torchtext.dataset : 텍스트 데이터셋 모음. IMDb, AG_NEWS 제공\n",
    "- torchvision.transforms : 여러 변환 필터를 담은 모듈. Tensor화, resize, crop, brightness 조절 가능\n",
    "- torchvision.utils : 이미지데이터를 저장하고 시각화 하기 위한 모듈"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da2004fe03f436a9a81b9c95e439c4add18d0165a64bc8b11e0efabfe79c313a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
