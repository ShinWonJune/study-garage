{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.save()\n",
    "- 학습의 결과를 저장하기 위한 함수\n",
    "- 모델 형태(architecture,  cnn 이라던가,,)와 parameter를 저장\n",
    "- 학습 중간과정의 저장을 통해 최선의 결과모델 선택\n",
    "- 외부 연구자와 공유\n",
    "<br><br>\n",
    "- model.state_dict() : 모델의 파라미터\n",
    "- .pt : pytorch에서 모델을 저장할 때 사용하는 확장자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### parameter만 저장하고 load\n",
    "- 모델이 동일 한 형태일 때 \n",
    "- 일반적으로 많이 사용됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "# Print model's tstate_dict\n",
    "print(\"model's state_dict:\")\n",
    "for param_tensor in model.state_dict(): #state_dict : 모델의 파라메터를 표시\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "# 모델의 파라메터를 저장\n",
    "torch.save(model.state_dict(),\n",
    "            # pytorch에서 모델을 저장할 때는 .pt 확장자 사용\n",
    "            os.path.join(MODEL_PATH,\"model.pt\"))\n",
    "\n",
    "new_model = TheModelClass()\n",
    "# 같은 모델의 형태가 보장될 때, parameter만 불러온다. load_state_dict 사용\n",
    "new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH,\"model.pt\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 architecture 함께 저장\n",
    "- 보통 많이 사용 안됨\n",
    "- 모델은 코드로 공유 되기 때문.\n",
    "- 결과를 공유할 때는 parameter만 저장하고 전달."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 architecture 와 함께 저장\n",
    "torch.save(model,os.path.join(MODEL_PATH,\"model.pt\"))\n",
    "# 모델의 architecture와 함께 load\n",
    "model = torch.load(os.path.join(MODEL_PATH,\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### checkpoints\n",
    "- 학습의 중간 결과를 저장하여 최선의 결과를 선택\n",
    "- earlystopping 기법 사용시 이전 학습의 결과물 저장\n",
    "- loss와 metric 값을 지속적으로 확인 저장\n",
    "- 일반적으로, epoch, loss, metric을 함께 저장하여 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict 타입으로 모델의 정보를 epoch과 함께 넣어주어 저장함\n",
    "from pickletools import optimize\n",
    "\n",
    "\n",
    "torch.save({\n",
    "        'epoch': e,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': epoch_loss,\n",
    "        # 파일명에 epoch_loss, epoch_acc를 명시\n",
    "        }, f\"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt\")\n",
    "\n",
    "#dict 처럼 접근해서 골라서 쓰면 된다.\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoc']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning\n",
    "- 다른 데이터셋으로 만든 모델을 현재 데이터에 적용(pretrained model 활용)\n",
    "- 일반적으로 대용량 데이터셋으로 만들어진 모델의 성능이 좋다\n",
    "- 현재의 DL에선 가장 일반적인 학습 기법\n",
    "- backbone architecture가 잘 학습된 모델에서 일부분만 변경하여 학습을 수행(fine tuning)\n",
    "    #### TorchVison에서 다양한 기본 모델 제공\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing\n",
    "- pretrained model 활용시, 모델의 일부분을 freeze 시킴\n",
    "- 특정 위치의 parameter를 얼려버리는 것\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vgg16 모델을 vgg에 할당하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#pretrained = True 해줘야 제대로 학습된 모델을 가져옴\n",
    "#to(device) : 저 device를 사용하여 연산하고 거기에 저장할거라는뜻.\n",
    "vgg = models.vgg16(pretrained = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위랑 관계없음. 그냥 코드만 보라.\n",
    "\n",
    "class MyNewNet(nn.Module):   \n",
    "    def __init__(self):\n",
    "        super(MyNewNet, self).__init__()\n",
    "        self.vgg19 = models.vgg19(pretrained=True)\n",
    "        # 내 데이터에 맞게 레이어들 추가.\n",
    "        # 개냐 고양이냐 를 맞추는 하나의 output이 되도록.\n",
    "        self.linear_layers = nn.Linear(1000, 1)\n",
    "\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.vgg19(x)        \n",
    "        return self.linear_layers(x)\n",
    "\n",
    "# freezing 시키는것. 학습하지 않도록.\n",
    "for param in my_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 학습시킬 새로운 layer만 required_grad = True 준다.\n",
    "for param in my_model.linear_layers.parameters():\n",
    "    param.requires_grad = True    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### validation/testing 할때 model.eval()\n",
    "#### training 할때, model.train() 해주자.\n",
    "my_model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "da2004fe03f436a9a81b9c95e439c4add18d0165a64bc8b11e0efabfe79c313a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
